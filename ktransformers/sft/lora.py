import transformers
from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq
from transformers import Trainer, TrainingArguments
from transformers.trainer import TRAINING_ARGS_NAME
from transformers.training_args import OptimizerNames, ParallelMode
from transformers.utils import (
    is_datasets_available,
    is_sagemaker_mp_enabled,
    is_torch_xpu_available,
    is_torch_mlu_available,
    is_torch_musa_available,
    is_torch_npu_available,
    is_torch_mps_available,
    is_torch_hpu_available,
    is_accelerate_available,
    is_apex_available,
    logging,
)
from torch.utils.data import DataLoader, IterableDataset
from transformers import Trainer
from transformers.trainer_utils import seed_worker
from transformers import TrainerCallback
from packaging import version
import os
import inspect
import functools
from typing import Union, Any

import torch
from torch.utils.data import DataLoader
from peft import LoraConfig, TaskType
from datasets import Dataset
from torchviz import make_dot
from torch.profiler import profile, record_function, ProfilerActivity
import torch.nn.functional as F
import torch.nn as nn
import gc
from tqdm import tqdm
import os, torch, json, tempfile
from pathlib import Path
from accelerate import Accelerator
if is_accelerate_available("0.28.0"):
    from accelerate.utils import DataLoaderConfiguration
from accelerate import __version__ as accelerate_version
if is_apex_available():
    from apex import amp
if version.parse(accelerate_version) > version.parse("1.3.0"):
        from accelerate.utils import TorchTensorParallelPlugin
if is_sagemaker_mp_enabled():
    from transformers.trainer_utils import smp_forward_backward

from ktransformers.sft.peft_utils.mapping import inject_adapter_in_model, get_peft_model
from ktransformers.sft.peft_utils.lora_layer import KTransformersLinearLora
from ktransformers.sft.flops_utils.custom_profile import custom_profile
from ktransformers.operators.experts import KExpertsTorch, KTransformersExperts
# from ktransformers.sft.load_lora import get_custom_peft_model

logger = logging.get_logger(__name__)

# FOR: not A or H GPU
os.environ["NCCL_P2P_DISABLE"]  = "1"
os.environ["NCCL_IB_DISABLE"]  = "1"
os.environ["KT_DEBUG_MOE"] = "1"

layer_data = {}  # å­˜å‚¨å„å±‚è¾“å…¥è¾“å‡ºæ•°æ®

def record_layer_io(module, input, output, layer_name):
    layer_data[layer_name] = {
        'input': input[0].detach().clone(),
        'output': output.detach().clone()
    }

# æ³¨å†Œé’©å­
hooks = []
target_layers = [
    'base_model.model.model.orig_module.layers.0.self_attn.kv_a_proj_with_mqa',
    'base_model.model.model.orig_module.layers.0.self_attn.kv_b_proj',
    # 'base_model.model.model.orig_module.layers.1.self_attn.kv_a_proj_with_mqa',
    # 'base_model.model.model.orig_module.layers.1.self_attn.kv_b_proj'
]


# è‡ªå®šä¹‰å›è°ƒï¼Œæ‰‹åŠ¨æ§åˆ¶Profilerï¼Œé¿å…transformeråº“ç‰ˆæœ¬å¤ªä½
class ProfilerCallback(TrainerCallback):
    def __init__(self, profiler):
        self.profiler = profiler

    def on_step_end(self, args, state, control, **kwargs):
        self.profiler.step()

def preprocess_function(batch, tokenizer, max_len=512):
    full_inputs = [ins + inp for ins, inp in zip(batch["instruction"], batch["input"])]
    
    # print(f"FI: {full_inputs}")
    # print(f"TFI: {type(full_inputs)}")
    tokenized_inputs = tokenizer(full_inputs, padding="max_length", truncation=True, max_length=max_len)
    tokenized_outputs = tokenizer(batch["output"], padding="max_length", truncation=True, max_length=max_len)

    # need batch=false, just for debug and test
    # print("ğŸ”¹Instruction tokens:", len(tokenizer.tokenize(instruction)))
    # print("ğŸ”¹Input tokens:", len(tokenizer.tokenize(inputs)))
    # print("ğŸ”¹Instruction+Input tokens:", len(tokenizer.tokenize(full_input)))
    # print("ğŸ”¸Output tokens (label):", len(tokenizer.tokenize(targets)))

    tokenized_inputs["labels"] = tokenized_outputs["input_ids"]
    return tokenized_inputs
    
class KAccelerator(Accelerator):
    def __init__(self, *args, **kwargs):
        kwargs.setdefault("device_placement", False)
        super().__init__(*args, **kwargs)
        
    def prepare_model(self, model, *args, **kwargs):
        return model
    
    def prepare(self, *args, **kwargs):
        prepped = []
        for obj in args:
            if isinstance(obj, nn.Module):
                prepped.append(self.prepare_model(obj, **kwargs))
            else:
                prepped.append(super().prepare(obj, **kwargs))
        return tuple(prepped) if len(prepped) > 1 else prepped[0]

class KTrainer(Trainer):
    def save_model(self, output_dir=None, _internal_call=False):
        output_dir = output_dir or self.args.output_dir
        os.makedirs(output_dir, exist_ok=True)
        # only save LoRA adapterï¼ˆinclude adapter_config.jsonï¼‰
        self.model.save_pretrained(output_dir)
        
    def _move_model_to_device(self, model, device):
        print("[KTrainer] Due to the placement feature in KTransformers, skip moving model to", device)
        return model
    
    # ç¦æ­¢ Trainer åœ¨ n_gpu>1 æ—¶å¥— DataParallel
    def _wrap_model(self, model, training=True, dataloader=None):
        self.model_wrapped = model
        return model
    
    def create_accelerator_and_postprocess(self):
        # We explicitly don't rely on the `Accelerator` to do gradient accumulation
        grad_acc_kwargs = {}
        if is_accelerate_available("0.28.0") and self.args.accelerator_config.gradient_accumulation_kwargs is not None:
            grad_acc_kwargs = self.args.accelerator_config.gradient_accumulation_kwargs

        # check if num_steps is attempted to be passed in gradient_accumulation_kwargs
        if "num_steps" in grad_acc_kwargs:
            if self.args.gradient_accumulation_steps > 1:
                # raise because we do not know which setting is intended.
                raise ValueError(
                    "The `AcceleratorConfig`'s `num_steps` is set but `gradient_accumulation_steps` is greater than 1 in the passed `TrainingArguments`"
                    "If using the passed `AcceleratorConfig` is desired, do not set the `TrainingArguments` `gradient_accumulation_steps`."
                )
            else:
                self.args.gradient_accumulation_steps = grad_acc_kwargs["num_steps"]

        accelerator_config = self.args.accelerator_config.to_dict()

        if is_accelerate_available("0.28.0"):
            # Extract dataloader config params from accelerator config
            dataloader_params = ["split_batches", "dispatch_batches", "even_batches", "use_seedable_sampler"]
            dataloader_config_dict = {param: accelerator_config.pop(param) for param in dataloader_params if param in accelerator_config}
            if DataLoaderConfiguration is None:
                raise ImportError("Your accelerate does not provide DataLoaderConfiguration but Trainer expects it.")
            dataloader_config = DataLoaderConfiguration(**dataloader_config_dict)
            if is_accelerate_available("1.1.0"):
                dataloader_config.data_seed = self.args.data_seed
        else:
            dataloader_config = None

        non_blocking = accelerator_config.pop("non_blocking", False)
        if not is_accelerate_available("0.30.0"):
            if non_blocking:
                raise ImportError(
                    "`non_blocking` is only supported in accelerate v0.30.0 and above. Please upgrade accelerate to use this feature."
                )
        else:
            if non_blocking and not self.args.dataloader_pin_memory:
                logger.warning("`non_blocking` is enabled but `dataloader_pin_memory` is not. For best performance, enable both.")
            if dataloader_config is not None:
                dataloader_config.non_blocking = non_blocking

        accelerator_config.pop("gradient_accumulation_kwargs", None)

        args = {
            "deepspeed_plugin": self.args.deepspeed_plugin,
            "device_placement": False,
        }

        if is_accelerate_available("0.28.0"):
            args["dataloader_config"] = dataloader_config
        else:
            args.update(accelerator_config)

        if getattr(self.args, "tp_size", 1) > 1:
            self.is_tp_enabled = True
            if version.parse(accelerate_version) > version.parse("1.3.0") and TorchTensorParallelPlugin is not None:
                args["torch_tp_plugin"] = TorchTensorParallelPlugin(tp_size=self.args.tp_size)
            else:
                raise ValueError("Requires accelerate>1.3.0 to use Tensor Parallelism.")

        self.accelerator = KAccelerator(**args)

        try:
            self.accelerator.state.device_ids = [0]
            self.accelerator.state.num_processes = 1
            self.accelerator.state.num_gpus = 1
        except Exception:
            pass

        # some Trainer classes need to use `gather` instead of `gather_for_metrics`, thus we store a flag
        self.gather_function = self.accelerator.gather_for_metrics

        if "use_gather_object" in inspect.signature(self.gather_function).parameters.keys():
            self.gather_function = functools.partial(
                self.gather_function, use_gather_object=self.args.eval_use_gather_object
            )

        # deepspeed and accelerate flags covering both trainer args and accelerate launcher
        self.is_deepspeed_enabled = getattr(self.accelerator.state, "deepspeed_plugin", None) is not None
        self.is_fsdp_enabled = getattr(self.accelerator.state, "fsdp_plugin", None) is not None
        self.is_tp_enabled = getattr(self.accelerator.state, "torch_tp_plugin", None) is not None
        # post accelerator creation setup
        if self.is_fsdp_enabled:
            fsdp_plugin = self.accelerator.state.fsdp_plugin
            for param in ["limit_all_gathers", "activation_checkpointing"]:
                setattr(fsdp_plugin, param, self.args.fsdp_config.get(param, getattr(fsdp_plugin, param)))
            if fsdp_plugin.activation_checkpointing and self.args.gradient_checkpointing:
                raise ValueError(
                    "The activation_checkpointing in FSDP config and the gradient_checkpointing in training arg "
                    "can't be set to True simultaneously. Please use FSDP's activation_checkpointing logic "
                    "when using FSDP."
                )

        if self.is_deepspeed_enabled and getattr(self.args, "hf_deepspeed_config", None) is None:
            self.propagate_args_to_deepspeed()

        # `save_only_model` can't be used with DeepSpeed/FSDP along with `load_best_model_at_end`
        if (
            self.args.save_only_model
            and (self.is_deepspeed_enabled or self.is_fsdp_enabled)
            and self.args.load_best_model_at_end
        ):
            wrapper = "DeepSpeed" if self.is_deepspeed_enabled else "FSDP"
            raise ValueError(f"{wrapper} can't be used with `save_only_model` along with `load_best_model_at_end`.")

        # `auto_find_batch_size` isn't supported yet with DeepSpeed Zero-3
        if (
            self.is_deepspeed_enabled
            and self.accelerator.state.deepspeed_plugin.zero_stage == 3
            and self.args.auto_find_batch_size
        ):
            raise ValueError(
                "`auto_find_batch_size` isn't supported yet with DeepSpeed Zero-3. Please consider using Zero-2, Zero-1, or FSDP"
            )
        if (
            self.args.save_only_model
            and self.is_fsdp_enabled
            and "SHARDED_STATE_DICT" in str(self.accelerator.state.fsdp_plugin.state_dict_type)
        ):
            raise ValueError("save_only_model option is not compatible with FSDP state dict type 'SHARDED_STATE_DICT'")
        
        if dataloader_config is not None:
            dataloader_config.split_batches = False
            dataloader_config.dispatch_batches = False
            dataloader_config.even_batches = False
            
    # â˜… æ ¸å¿ƒä¿®æ­£ï¼šè®­ç»ƒ DataLoader çš„ batch_size å›ºå®šç”¨ per_deviceï¼Œä¸ä¹˜ n_gpu
    def get_train_dataloader(self) -> DataLoader:
        """
        Returns the training DataLoader with per_device_train_batch_size
        (no implicit multipliers by number of visible GPUs).
        """
        if self.train_dataset is None:
            raise ValueError("Trainer: training requires a train_dataset.")

        train_dataset = self.train_dataset
        data_collator = self.data_collator

        # ä¸åŸç”Ÿä¸€è‡´ï¼šåŸºäº datasets çš„ç§»é™¤æ— ç”¨åˆ—ï¼›å¦åˆ™åŒ…ä¸€å±‚å‰”åˆ—çš„ collator
        if is_datasets_available():
            try:
                import datasets  # ä»…ç”¨äº isinstance æ£€æŸ¥
                if isinstance(train_dataset, datasets.Dataset):
                    train_dataset = self._remove_unused_columns(train_dataset, description="training")
                else:
                    data_collator = self._get_collator_with_removed_columns(data_collator, description="training")
            except Exception:
                # datasets ä¸å¯ç”¨æˆ–ç‰ˆæœ¬ä¸å…¼å®¹æ—¶ï¼Œé€€åŒ–åˆ°å‰”åˆ— collator
                data_collator = self._get_collator_with_removed_columns(data_collator, description="training")
        else:
            data_collator = self._get_collator_with_removed_columns(data_collator, description="training")

        # è¿™é‡Œä¸åŸç”Ÿä¸åŒï¼šbatch_size ç”¨ per_deviceï¼Œä¸ç”¨ self._train_batch_size
        dataloader_params = {
            "batch_size": self.args.per_device_train_batch_size,   # â˜… ä¸ä¹˜ n_gpu
            "collate_fn": data_collator,
            "num_workers": self.args.dataloader_num_workers,
            "pin_memory": self.args.dataloader_pin_memory,
            "persistent_workers": self.args.dataloader_persistent_workers,
        }

        # é IterableDataset æ—¶ï¼Œè¡¥å…… sampler / drop_last / worker_init_fn / prefetch_factor
        if not isinstance(train_dataset, IterableDataset):
            dataloader_params["sampler"] = self._get_train_sampler()
            dataloader_params["drop_last"] = self.args.dataloader_drop_last
            dataloader_params["worker_init_fn"] = seed_worker
            # ä»…å½“ num_workers>0 ä¸”è®¾ç½®äº† prefetch_factor æ—¶æ‰ä¼ ï¼ˆä¸ torch DataLoader è¦æ±‚ä¸€è‡´ï¼‰
            if self.args.dataloader_num_workers > 0 and self.args.dataloader_prefetch_factor is not None:
                dataloader_params["prefetch_factor"] = self.args.dataloader_prefetch_factor

        dl = DataLoader(train_dataset, **dataloader_params)

        # ä¸ºäº†å®Œå…¨æ˜¾å¼ï¼Œå‘Šè¯‰ Accelerate ä¸è¦åš device_placement
        try:
            prepared = self.accelerator.prepare(dl, device_placement=[False])
        except TypeError:
            # æŸäº› accelerate ç‰ˆæœ¬æ²¡æœ‰ device_placement å‚æ•°ï¼Œç›´æ¥ prepare
            prepared = self.accelerator.prepare(dl)

        return prepared
    
    # === è®­ç»ƒæ­¥ï¼šä¸åŸç”Ÿä¸€è‡´ï¼Œå”¯ä¸€æ”¹åŠ¨æ˜¯æœ€åè¿”å›æ—¶æŠŠ loss æŒªåˆ° self.args.device ===
    def training_step(
        self,
        model: torch.nn.Module,
        inputs: dict[str, Union[torch.Tensor, Any]],
        num_items_in_batch=None
    ) -> torch.Tensor:
        model.train()
        if hasattr(self.optimizer, "train") and callable(self.optimizer.train):
            self.optimizer.train()

        # â˜… å…³é”®ï¼šä¿ç•™åŸç”Ÿçš„æ•°æ®å‡†å¤‡ï¼ˆä¼šæŠŠ batch å¼ é‡æ”¾åˆ° self.args.deviceï¼Œ
        #  ä½ çš„è‡ªå®šä¹‰ç®—å­/æ›¿æ¢æ¨¡å—å¾ˆå¤šæ˜¯æ®æ­¤å†³å®šå†…éƒ¨æµå‘çš„ï¼‰
        inputs = self._prepare_inputs(inputs)

        if is_sagemaker_mp_enabled():
            loss_mb = smp_forward_backward(model, inputs, self.args.gradient_accumulation_steps)
            # â˜… è¿”å›å€¼æ”¾åˆ° args.deviceï¼Œç›´æ¥æ»¡è¶³ HF çš„è®¾å¤‡æ£€æŸ¥
            return loss_mb.reduce_mean().detach().to(self.args.device)

        # ä¸åŸç”Ÿä¸€è‡´çš„ä¸Šä¸‹æ–‡ï¼ˆamp/autocast ç­‰ï¼‰
        with self.compute_loss_context_manager():
            loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)

        # é‡Šæ”¾ batch
        del inputs

        # åŸç”Ÿçš„ empty_cache æ­¥éª¤ï¼ˆç…§æŠ„ï¼‰
        if (
            self.args.torch_empty_cache_steps is not None
            and self.state.global_step % self.args.torch_empty_cache_steps == 0
        ):
            if is_torch_xpu_available():
                torch.xpu.empty_cache()
            elif is_torch_mlu_available():
                torch.mlu.empty_cache()
            elif is_torch_musa_available():
                torch.musa.empty_cache()
            elif is_torch_npu_available():
                torch.npu.empty_cache()
            elif is_torch_mps_available(min_version="2.0"):
                torch.mps.empty_cache()
            elif is_torch_hpu_available():
                logger.warning(
                    "`torch_empty_cache_steps` is set but HPU device/backend does not support empty_cache()."
                )
            else:
                torch.cuda.empty_cache()

        kwargs = {}

        # LOMO éœ€è¦å­¦ä¹ ç‡
        if self.args.optim in [OptimizerNames.LOMO, OptimizerNames.ADALOMO]:
            kwargs["learning_rate"] = self._get_learning_rate()

        # å¤šå¡æ•°æ®å¹¶è¡Œæƒ…å†µä¸‹åšå‡å€¼ï¼ˆä½ ç°åœ¨æ˜¯æ¨¡å‹å¹¶è¡Œï¼Œä½†ä¿æŒå…¼å®¹ï¼‰
        if self.args.n_gpu > 1:
            loss = loss.mean()

        # Apex/amp è·¯å¾„
        if self.use_apex:
            with amp.scale_loss(loss, self.optimizer) as scaled_loss:  # type: ignore
                scaled_loss.backward()
        else:
            # ä¸åŸç”Ÿä¸€è‡´ï¼šå½“ loss ä¸æ˜¯ç”¨æˆ·è‡ªå®šä¹‰è®¡ç®—æ—¶ï¼ŒæŒ‰æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ç¼©æ”¾
            if not self.model_accepts_loss_kwargs and self.compute_loss_func is None:
                loss = loss / self.args.gradient_accumulation_steps

            # DeepSpeed å…³é—­ gas ç¼©æ”¾
            if getattr(self.accelerator, "distributed_type", None) and \
               str(self.accelerator.distributed_type) == "DistributedType.DEEPSPEED":
                kwargs["scale_wrt_gas"] = False

            self.accelerator.backward(loss, **kwargs)

        # â˜… å”¯ä¸€æ”¹åŠ¨ï¼šè¿”å›ç»™ Trainer çš„ loss å¿…é¡»åœ¨ self.args.device
        ret = loss.detach()
        if ret.device != self.args.device:
            ret = ret.to(self.args.device, non_blocking=True)

        # ä¸€æ¬¡æ€§è°ƒè¯•ï¼ˆå¯å¼€ `KT_DBG_STEP=1` æŸ¥çœ‹ï¼‰
        if os.environ.get("KT_DBG_STEP", "0") == "1" and not hasattr(self, "_kt_dbg_once"):
            try:
                print(f"[KT-DBG] args.device={self.args.device}  loss(before)={loss.device}  loss(return)={ret.device}")
            except Exception:
                pass
            self._kt_dbg_once = True

        return ret

def _short(t):
    return tuple(t.shape) if isinstance(t, torch.Tensor) else type(t)

def install_shape_probes(model):
    if os.environ.get("KT_DEBUG_MOE","0") != "1":
        print("[KT_DEBUG_MOE] off"); return

    # 0) æ‰“å° DataLoader é…ç½®ä½ å·²ç»æœ‰äº†ï¼Œè¿™é‡Œå†è´´ä¸€éä¿é™©
    try:
        acc = trainer.accelerator
        cfg = getattr(acc, "dataloader_config", None)
        if cfg is not None:
            print("[ACCEL DL CONFIG]",
                  "split_batches=", getattr(cfg,"split_batches",None),
                  "dispatch_batches=", getattr(cfg,"dispatch_batches",None),
                  "even_batches=", getattr(cfg,"even_batches",None),
                  "use_seedable_sampler=", getattr(cfg,"use_seedable_sampler",None),
                  "non_blocking=", getattr(cfg,"non_blocking",None))
    except Exception as e:
        print("[ACCEL DL CONFIG] <err>", e)

    # 1) åœ¨ embed_tokens å…¥å£æ‰“å° input_ids çš„ (B,S)
    try:
        emb = model.base_model.model.model.embed_tokens
        def _emb_pre(mod, inp):
            x = inp[0]
            if not hasattr(mod, "_dbg_once"):
                print(f"[DBG] embed input_ids shape = {tuple(x.shape)}  (expect B,S)")
                mod._dbg_once = True
        emb.register_forward_pre_hook(_emb_pre)
    except Exception as e:
        print("[DBG] embed hook failed:", e)

    # 2) åœ¨ç¬¬ 0 ä¸ª decoder layer å…¥å£/å‡ºå£æ‰“å° hidden_states å½¢çŠ¶
    try:
        first_layer = model.base_model.model.model.layers[0]
        _orig_fwd = first_layer.forward
        def _wrap_fwd(self, *args, **kwargs):
            hs = args[0] if args else kwargs.get("hidden_states")
            if not hasattr(self, "_dbg_once_in"):
                print(f"[DBG] L0.in hidden_states = {_short(hs)}  (expect B,S,H)")
                self._dbg_once_in = True
            out = _orig_fwd(*args, **kwargs)
            hs_out = out[0] if isinstance(out, (tuple, list)) else out
            if not hasattr(self, "_dbg_once_out"):
                print(f"[DBG] L0.out hidden_states = {_short(hs_out)}")
                self._dbg_once_out = True
            return out
        first_layer.forward = MethodType(_wrap_fwd, first_layer)
    except Exception as e:
        print("[DBG] L0 wrap failed:", e)

    # 3) åœ¨ä¸€ä¸ª MoE å±‚çš„ mlp å…¥å£æ‰“å°ï¼ˆDeepseekV3 çš„ mlp æ˜¯ MoEï¼‰
    try:
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå« MoE çš„å±‚ï¼ˆåå­—å¯èƒ½æ˜¯ .mlp æˆ–ä½ è‡ªå®šä¹‰ç±»ï¼‰
        moe_layer = None
        for i, lyr in enumerate(model.base_model.model.model.layers):
            if hasattr(lyr, "mlp"):
                moe_layer = lyr.mlp
                moe_idx = i
                break
        if moe_layer is not None:
            _moe_orig = moe_layer.forward
            def _moe_wrap(self, *args, **kwargs):
                x = args[0] if args else kwargs.get("hidden_states")
                if not hasattr(self, "_dbg_once"):
                    # è¿™é‡Œå¾ˆå¤š MoE å®ç°ä¼šæŠŠ (B,S,H) å±•å¹³æˆ (B*S,H) å†åš gate
                    print(f"[DBG] MLP(in) @layer{moe_idx} hidden_states = {_short(x)}")
                    if isinstance(x, torch.Tensor) and x.dim() == 3:
                        B,S,H = x.shape
                        print(f"[DBG] tokens before flatten = B*S = {B}*{S} = {B*S}")
                    self._dbg_once = True
                return _moe_orig(*args, **kwargs)
            moe_layer.forward = MethodType(_moe_wrap, moe_layer)
        else:
            print("[DBG] no moe_layer found")
    except Exception as e:
        print("[DBG] moe wrap failed:", e)

    # 4) åœ¨ KTransformersExperts å…¥å£æ‰“å° (N, â€¦) ä¸ expert_ids/weights å½¢çŠ¶ï¼ˆä½ ä¹‹å‰è£…è¿‡ï¼Œè¿™é‡Œæ›´å®Œæ•´ï¼‰
    try:
        from ktransformers.operators.experts import KTransformersExperts
        def _experts_pre(mod, args):
            if hasattr(mod, "_dbg_once"): return
            try:
                input_tensor, expert_ids, weights = args[:3]
                print(f"[DBG] experts.in input_tensor={tuple(input_tensor.shape)} "
                      f"expert_ids={tuple(expert_ids.shape)} weights={tuple(weights.shape)}")
                if input_tensor.dim()==2:
                    N = input_tensor.shape[0]
                    print(f"[DBG] N(input rows)={N}")
                if expert_ids.dim()==2:
                    T,K = expert_ids.shape
                    print(f"[DBG] tokens(T)={T}, K={K}, T*K={T*K}")
                mod._dbg_once = True
            except Exception as e:
                print("[DBG] experts hook parse err:", e)
        count=0
        for name,m in model.named_modules():
            if isinstance(m, KTransformersExperts):
                m.register_forward_pre_hook(_experts_pre); count+=1
        print(f"[KT_DEBUG_MOE] installed experts hook on {count} modules.")
    except Exception as e:
        print("[DBG] experts hook failed:", e)

def inspect_device(model, write_file):
    for name, module in model.named_modules(): 
        with open(write_file, 'a') as file:
            file.write(f"Layer: {name}\n")
        # print(f"Layer: {name}")
        # æ£€æŸ¥å‚æ•° 
        for param_name, param in module.named_parameters(recurse=False): 
            with open(write_file, 'a') as file:
                file.write(f"  Parameter '{param_name}' device: {param.device}\n")
            # print(f"  Parameter '{param_name}' device: {param.device}") 
        # æ£€æŸ¥ç¼“å†²åŒºï¼ˆå¦‚BatchNormçš„running_meanï¼‰
        for buffer_name, buffer in module.named_buffers(recurse=False): 
            with open(write_file, 'a') as file:
                file.write(f"  Buffer '{buffer_name}' device: {buffer.device}\n")
            # print(f"  Buffer '{buffer_name}' device: {buffer.device}")

def print_model_params(model):
    # éå†æ‰€æœ‰Decoderå±‚ï¼ˆå…±27å±‚ï¼‰
    # for layer_idx in range(len(model.model.orig_module.layers)):
    for layer_idx in range(0, 3):
        layer = model.model.orig_module.layers[layer_idx]
        
        # ============= æ‰“å°æ³¨æ„åŠ›å±‚å‚æ•° =============
        print(f"\n================ Layer {layer_idx} Attention ================")
        
        # æ‰“å°q_projå‚æ•°
        q_proj = layer.self_attn.orig_module.q_proj.orig_module
        print(f"\nq_proj.generate_linear.weight (shape: {q_proj.generate_linear.weight.shape})")
        print(q_proj.generate_linear.weight.cpu())
        
        # # æ‰“å°kv_a_projå‚æ•°
        # kv_a_proj = layer.self_attn.orig_module.kv_a_proj_with_mqa.orig_module
        # print(f"\nkv_a_proj.weight (shape: {kv_a_proj.weight.shape})")
        # print(kv_a_proj.weight.data[:3, :5].detach().cpu().numpy())
        
        # # æ‰“å°o_projå‚æ•°
        # o_proj = layer.self_attn.orig_module.o_proj.orig_module
        # print(f"\no_proj.weight (shape: {o_proj.weight.shape})")
        # print(o_proj.weight.data[:3, :5].detach().cpu().numpy())
        
        # # ============= æ‰“å°MLP/MoEå‚æ•° =============
        # print(f"\n================ Layer {layer_idx} MLP/MoE ================")
        
        # # åŒºåˆ†æ™®é€šMLPå’ŒMoEå±‚ï¼ˆç¬¬0å±‚æ˜¯æ™®é€šMLPï¼Œå…¶ä»–æ˜¯MoEï¼‰
        # if layer_idx == 0:
        #     # æ™®é€šMLPå±‚å‚æ•°
        #     mlp = layer.mlp
        #     for proj_type in ['gate_proj', 'up_proj', 'down_proj']:
        #         module = getattr(mlp, proj_type).orig_module
        #         print(f"\n{proj_type}.weight (shape: {module.weight.shape})")
        #         print(module.weight.data[:3, :5].detach().cpu().numpy())
        # else:
        #     # MoEå±‚å‚æ•°
        #     moe = layer.mlp.orig_module
        #     # æ‰“å°å…±äº«ä¸“å®¶å‚æ•°
        #     print("\n[Shared Experts]")
        #     for proj_type in ['gate_proj', 'up_proj', 'down_proj']:
        #         module = getattr(moe.shared_experts, proj_type).orig_module
        #         print(f"\nshared_{proj_type}.weight (shape: {module.weight.shape})")
        #         print(module.weight.data[:3, :5].detach().cpu().numpy())
            
        #     # æ‰“å°64ä¸ªä¸“å®¶å‚æ•°ï¼ˆé‡‡æ ·å‰3ä¸ªï¼‰
        #     print("\n[Experts]")
        #     for expert_idx in range(3):  # é‡‡æ ·å‰3ä¸ªä¸“å®¶
        #         expert = moe.experts.orig_module[expert_idx]
        #         print(f"\nExpert {expert_idx}:")
        #         for proj_type in ['gate_proj', 'up_proj', 'down_proj']:
        #             module = getattr(expert, proj_type)
        #             print(f"{proj_type}.weight (shape: {module.weight.shape})")
        #             print(module.weight.data[:3, :5].detach().cpu().numpy())

def print_lora_params(model):
    # éå†æ‰€æœ‰Decoderå±‚ (ç´¢å¼•0åˆ°26å…±27å±‚)
    # for layer_idx in range(len(model.model.orig_module.layers)):
    for layer_idx in range(0, 3):
        # è·å–å½“å‰Decoderå±‚
        layer = model.base_model.model.model.orig_module.layers[layer_idx]
        # layer = model.model.orig_module.layers[layer_idx]
        
        # å®šä½åˆ°ç›®æ ‡æ¨¡å—è·¯å¾„
        q_proj_module = layer.self_attn.orig_module.q_proj.orig_module
        
        # æå–ç›®æ ‡çŸ©é˜µå‚æ•°
        linear_weight = q_proj_module.generate_linear.weight
        lora_A_weight = q_proj_module.lora_A["default"].weight
        lora_B_weight = q_proj_module.lora_B["default"].weight
        
        # æ‰“å°å‚æ•°ä¿¡æ¯
        print(f"\n=================== Layer {layer_idx} ===================")
        
        # æ‰“å°åŸLinearçŸ©é˜µå‚æ•°
        print("\nOriginal Linear (first row slice):")
        print(linear_weight.cpu())  # ç¬¬ä¸€è¡Œå‰5ä¸ªå‚æ•°
        
        # æ‰“å°Lora_Aå‚æ•°
        print("\nLora_A (first row slice):")
        print(lora_A_weight.cpu())  # ç¬¬ä¸€è¡Œå‰5ä¸ªå‚æ•°
        
        # æ‰“å°Lora_Bå‚æ•°
        print("\nLora_B (first row slice):")
        print(lora_B_weight.cpu())  # ç¬¬ä¸€è¡Œå‰5ä¸ªå‚æ•°

def print_grad_fn(grad_fn, indent=0):
    """é€’å½’æ‰“å°è®¡ç®—å›¾èŠ‚ç‚¹"""
    if grad_fn is None:
        return
    # æ‰“å°å½“å‰èŠ‚ç‚¹ä¿¡æ¯
    print(' ' * indent, f"Node: {str(grad_fn).split('(')[0]}")
    print(' ' * indent, f"  Metadata: {grad_fn.metadata}")
    # éå†å­èŠ‚ç‚¹
    for child in getattr(grad_fn, 'next_functions', []):
        if child[0] is not None:
            print_grad_fn(child[0], indent + 2)

def forward_hook(module, inputs, output):
    if isinstance(output, (tuple, list)):
        for i, o in enumerate(output):
            if o is None:
                print(f"{module.__class__.__name__} output index {i} is None")
            else:
                print(f"{module.__class__.__name__} output index {i}: requires_grad={o.requires_grad}, grad_fn={o.grad_fn}")
    elif output is None:
        print(f"{module.__class__.__name__} returned None")
    else:
        print(f"{module.__class__.__name__}: requires_grad={output.requires_grad}, grad_fn={output.grad_fn}")

def check_moe_gradients(model):
    moe_layer = model.base_model.model.model.orig_module.layers[1].mlp.orig_module
    for name, param in moe_layer.named_parameters():
        if param.requires_grad and param.grad is not None:
            grad_norm = torch.norm(param.grad)
            print(f"MoEå‚æ•° {name} æ¢¯åº¦èŒƒæ•°: {grad_norm}")
        else:
            print(f"MoEå‚æ•° {name} æ— æ¢¯åº¦")

def disable_all_dropout(module):
        for name, child in module.named_children():
            if isinstance(child, nn.Dropout):
                child.p = 0  # ç›´æ¥ä¿®æ”¹æ¦‚ç‡å‚æ•°
                child.inplace = False  # ç¡®ä¿ä¸å½±å“åŸå§‹æ•°æ®
            disable_all_dropout(child)  # é€’å½’å¤„ç†å­æ¨¡å—

def verify_lora_layers(model):
    for layer_path in target_layers:
        # è·å–æ¨¡å—å®ä¾‹
        module = model.get_submodule(layer_path)
        orig_module = module.orig_module
        
        # æå–å‚æ•°
        W = orig_module.weight.data  # [576, 2048] -> [2048, 576]
        lora_A = module.lora_A['default'].weight.data  # [8, 2048]
        lora_B = module.lora_B['default'].weight.data  # [576, 8]
        alpha_over_r = 32/8  # alpha=32, r=8
        
        # è·å–è®°å½•çš„æ•°æ®ï¼ˆä¿æŒbatchç»´åº¦ï¼‰
        input_tensor = layer_data[layer_path]['input']  # [1, 512, 2048]
        
        # æ‰‹åŠ¨è®¡ç®—æµç¨‹
        # åŸå§‹éƒ¨åˆ†è®¡ç®—
        try:
            original_output = torch.matmul(input_tensor, W)  # [1,512,2048] @ [2048,576] => [1,512,576]
        except:
            original_output = torch.matmul(input_tensor, W.T)  # [1,512,2048] @ [2048,576] => [1,512,576]
        
        # LoRAéƒ¨åˆ†è®¡ç®—
        lora_effect = torch.matmul(
            torch.matmul(input_tensor, lora_A.T),  # [1,512,2048] @ [2048,8] => [1,512,8]
            lora_B.T  # [1,512,8] @ [8,576] => [1,512,576]
        ) * alpha_over_r
        
        # åˆå¹¶ç»“æœ
        manual_output = original_output + lora_effect  # [1,512,576]
        
        # è·å–æ¨¡å‹è¾“å‡º
        model_output = layer_data[layer_path]['output']

        print(f"manual_output:{manual_output}")
        print(f"model_output:{model_output}")
        
        # æ•°å€¼æ¯”è¾ƒ
        if torch.allclose(manual_output, model_output, atol=1e-5):
            print(f"{layer_path} éªŒè¯é€šè¿‡")
        else:
            print(f"{layer_path} éªŒè¯å¤±è´¥ï¼æœ€å¤§è¯¯å·®ï¼š{torch.max(torch.abs(manual_output - model_output))}")

def print_moe_stats(moe_layer: KExpertsTorch):
    print(f"Total Params: {moe_layer.total_params/1e6:.2f}M")
    
    total_time = sum(moe_layer.times)
    gflops = (moe_layer.total_flops / 1e9) / total_time if total_time !=0 else 0
    
    print(f"Total Calls: {moe_layer.call_count}")
    # print(f"Avg GFLOPS per Call: {gflops/moe_layer.call_count:.2f}")
    print(f"Overall GFLOPS: {gflops:.2f}")
    
    # æ‰“å°å•æ¬¡è°ƒç”¨ç¤ºä¾‹
    if moe_layer.call_count > 0:
        last_flops = moe_layer.flops_per_call[-1]
        last_time = moe_layer.times[-1]
        print(f"\nLast Call - FLOPs: {last_flops/1e9:.2f}G  Time: {last_time*1000:.2f}ms  "
              f"GFLOPS: {(last_flops/1e9)/last_time:.2f}")
        
def recursive_traverse(model, parent_name=''):
    """
    é€’å½’éå†æ¨¡å‹ï¼ŒæŸ¥æ‰¾MoEå±‚å¹¶è°ƒç”¨print_moe_statsã€‚
    """
    # éå†æ¨¡å‹ä¸­çš„æ‰€æœ‰å­æ¨¡å—
    for name, module in model.named_children():
        full_name = f"{parent_name}.{name}" if parent_name else name
        
        # å¦‚æœæ˜¯ MoE å±‚ï¼Œè°ƒç”¨ print_moe_stats
        if isinstance(module, KTransformersExperts):  # æ£€æŸ¥æ˜¯å¦ä¸º MoE å±‚
            print(f"Found MoE layer: {full_name}")
            print_moe_stats(module.generate_experts)
        
        # é€’å½’å¤„ç†å­æ¨¡å—
        recursive_traverse(module, full_name)

def log_step_state(
    step: int,
    inputs: dict,
    loss: torch.Tensor,
    model: nn.Module,
    log_dir: str = "train_logs",
):
    """
    æŠŠå½“å‰ step çš„è¾“å…¥ / loss / grad / param ä¿å­˜åˆ° log_dir/step_{step}.pt
    """
    Path(log_dir).mkdir(parents=True, exist_ok=True)

    # â‘  å¤„ç†è¾“å…¥ï¼šåªä¿å­˜å¼ é‡ï¼Œä¸”å…ˆæ¬åˆ° CPUï¼Œé¿å… GPU è¿›ç¨‹é—´åºåˆ—åŒ–é—®é¢˜
    logged_inputs = {
        k: v.detach().cpu()
        for k, v in inputs.items()
        if isinstance(v, torch.Tensor)
    }

    # â‘¡ loss ä¸€èˆ¬æ˜¯æ ‡é‡ Tensor
    loss_val = loss.detach().cpu()

    # â‘¢ å‚æ•°ä¸æ¢¯åº¦
    params, grads = {}, {}
    for name, p in model.named_parameters():
        params[name] = p.detach().cpu()
        grads[name] = p.grad.detach().cpu() if p.grad is not None else None

    torch.save(
        {
            "step": step,
            "inputs": logged_inputs,
            "loss": loss_val,
            "params": params,
            "grads": grads,
        },
        f"{log_dir}/step_{step:08d}.pt",
    )

def collect_gradients(model, input_ids):
    # ç¡®ä¿å¯å¤ç°æ€§
    torch.manual_seed(42)
    
    output = model(input_ids=input_ids)
    
    logits = output.logits
    loss = logits.mean()
    
    # åå‘ä¼ æ’­
    model.zero_grad()
    loss.backward()
    
    # æ”¶é›†æ¢¯åº¦ä¿¡æ¯
    grads = []
    for name, param in model.named_parameters():
        if param.requires_grad and param.grad is not None:
            grads.append(f"{name}: {param.grad.norm().item():.6f}")
    
    return grads

def report_meta_tensors(model):
    import torch, inspect
    meta_modules = []
    for mod_name, mod in model.named_modules():
        metas = []
        # ä»…æ£€æŸ¥å½“å‰æ¨¡å—è‡ªèº«ï¼ˆä¸é€’å½’ï¼‰æŒ‚è½½çš„å‚æ•°/ç¼“å†²
        for n, p in list(mod.named_parameters(recurse=False)):
            if getattr(p, "is_meta", False) and p.is_meta:
                metas.append(("param", n, tuple(p.shape)))
        for n, b in list(mod.named_buffers(recurse=False)):
            if getattr(b, "is_meta", False) and b.is_meta:
                metas.append(("buffer", n, tuple(b.shape)))
        if metas:
            print(f"[META] {mod_name} ({type(mod).__name__}): {metas}")
            meta_modules.append((mod_name, type(mod).__name__, metas))
    return meta_modules

def lora_and_load_adapter(model, tokenizer, sft_data_path, save_adapter_path, is_profiler=False):

    torch.autograd.set_detect_anomaly(True) # åœ¨åå‘ä¼ æ’­å‡ºé”™æ—¶ï¼ŒPyTorch ä¼šæä¾›æ›´è¯¦ç»†çš„å †æ ˆä¿¡æ¯
    
    # tokenizer = AutoTokenizer.from_pretrained('/data/model/Qwen2.5-7B-Instruct', trust_remote_code=True)

    dataset = Dataset.from_json(sft_data_path)

    processed_dataset = dataset.map(lambda  examples: preprocess_function(examples, tokenizer), batched=True)
    split_dataset = processed_dataset.train_test_split(test_size=0.1)

    train_dataset = split_dataset["train"]
    val_dataset = split_dataset["test"]

    train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False)
    # val_dataloader = DataLoader(val_dataset, batch_size=8)

    lora_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM,
        target_modules=[ # TODO: è¿™é‡Œéœ€è¦å†™å…¥åˆ°shellé‡Œé¢ï¼Œæ¯ä¸ªæ¨¡å‹çš„templateæ˜¯ä¸ä¸€æ ·çš„
            # "q_proj", # FOR DeepSeek-V2-Lite
            "q_a_proj", # FOR DeepSeek-V3&R1
            "q_b_proj",
            "kv_a_proj_with_mqa",
            "kv_b_proj",
            "o_proj",
            "mlp.gate_proj",
            "mlp.up_proj",
            "mlp.down_proj",
            "shared_experts.gate_proj",
            "shared_experts.up_proj",
            "shared_experts.down_proj",
        ],
        r=8,
        lora_alpha=32,
        lora_dropout=0.1,
    )

    training_args = TrainingArguments(
        output_dir=save_adapter_path,
        per_device_train_batch_size=1,
        gradient_accumulation_steps=16,
        num_train_epochs=1,
        # max_steps=4, # TODO: FOR TEST, will override any value given in num_train_epochs
        learning_rate=3e-4,
        fp16=False,
        logging_steps=10,
        save_steps=1000,
        dataloader_drop_last=True,
        ddp_find_unused_parameters=False,
    )
    
    # model = inject_adapter_in_model(lora_config, model)
    model = get_peft_model(model, lora_config)
    # model = get_custom_peft_model(model, lora_config)

    model.config.use_cache = False

    model.print_trainable_parameters() 
    
    # print(f"model:{model}")
    # return
    
    # output = model(input_ids=torch.tensor([[1,2,3]], dtype=torch.int32, device="cuda:0"))
    # loss = output.logits.mean()
        
    # dot = make_dot(loss, params=dict(model.named_parameters()))
    # dot.render("KT_compute_cpuinfer_moe_model_graph", format="svg")
    
    # _ = report_meta_tensors(model)
    
    print("=== SAMPLE INSPECT ===")
    for i in range(2):
        ex = train_dataset[i]  # HF datasets çš„å•æ¡æ ·æœ¬ï¼ˆå·²ç»è¿‡ preprocess_functionï¼‰
        summary = {}
        for k,v in ex.items():
            if isinstance(v, list):
                if len(v)>0 and isinstance(v[0], list):
                    summary[k] = f"list-of-lists len={len(v)} x len0={len(v[0])}"
                else:
                    summary[k] = f"list len={len(v)}"
            elif torch.is_tensor(v):
                summary[k] = f"tensor shape={tuple(v.shape)}"
            else:
                summary[k] = str(type(v))
        print(f"[SAMPLE {i}]", summary)
    
    trainer = KTrainer(
        model=model,
        train_dataset=train_dataset,
        args=training_args,
        data_collator=DataCollatorForSeq2Seq(
            tokenizer, pad_to_multiple_of=8, return_tensors="pt", padding=True
        )
    )
    # trainer.accelerator = Accelerator(device_placement=False)
    # first_batch = next(iter(trainer.get_train_dataloader()))
    # print("Batch keys:", list(first_batch.keys()))
    
    # acc = KAccelerator(device_placement=False)
    # acc.state.device_ids = [0]
    # acc.state.num_processes = 1
    # acc.state.num_gpus = 1
    # trainer.accelerator = acc

    print("Accelerator device_ids:", trainer.accelerator.state.device_ids)
    print(f"type(trainer.model):{type(trainer.model)}")
    print(f"type(trainer.accelerator):{type(trainer.accelerator)}")
    
    _ = trainer._wrap_model(trainer.model, training=True)
    assert not isinstance(trainer.model, nn.DataParallel), "Model was wrapped with DataParallel unexpectedly"
    
    print("WRAP FUNC:", KTrainer._wrap_model is Trainer._wrap_model)   # åº”ä¸º False
    print("IS DP:", isinstance(trainer.model, nn.DataParallel))         # åº”ä¸º False
    print("IS DP WRAPPED:", isinstance(getattr(trainer, "model_wrapped", None), nn.DataParallel))  # åº”ä¸º False
    
    print("-------------------------START TRAINING!!!-------------------------")

    cfg = getattr(trainer.accelerator, "dataloader_config", None)
    print(
        "[ACCEL DL CONFIG]",
        "split_batches=", getattr(cfg, "split_batches", None),
        "dispatch_batches=", getattr(cfg, "dispatch_batches", None),
        "even_batches=", getattr(cfg, "even_batches", None),
        "use_seedable_sampler=", getattr(cfg, "use_seedable_sampler", None),
        "non_blocking=", getattr(cfg, "non_blocking", None),
    )
    print("--------------------NEW DEBUG--------------------")
    # install_shape_probes(trainer.model) # print some debug info about multi-gpu placement.
    trainer.train()

    # input_ids = torch.randint(0, 1000, (32, 128), device="cuda:0")
    # gradients = collect_gradients(model, input_ids)
    
    # with open(f"/home/lpl/KT-SFT/tmp/KSFTExpertsCPU_grads.txt", "w") as f:
    #     f.write("\n".join(gradients))
    # print(xx)
    
    # -----------------æ¨¡å‹è¾“å…¥æ•°æ®æµ‹è¯•-----------------
    # total_length = 0
    # valid_count = 0
    # for batch in tqdm(train_dataloader):
    #     input_ids = batch['input_ids']
    #     # print(f"Token count per sample: {[len(ids) for ids in input_ids]}")
    #     for ids in input_ids:
    #         if not torch.equal(ids, torch.tensor([100001])):
    #             total_length += len(ids)
    #     valid_count += 1
    #     # print(f"Input tensor: {input_ids}")
    #     # print(f"total_length:{total_length}")
    #     # break

    # if valid_count > 0:
    #     average_length = total_length / valid_count
    #     print(f"å¹³å‡é•¿åº¦: {average_length}")
    # else:
    #     print("æ²¡æœ‰æœ‰æ•ˆçš„ input_ids å…ƒç´ ã€‚")

    # print(xx)
    # -----------------æ¨¡å‹è¾“å…¥æ•°æ®æµ‹è¯•-----------------
    
    # -----------------æ¨¡å‹FLOPSæµ‹è¯•ï¼ˆTHOPæ–¹æ³•ï¼‰-----------------
    # æ²¡æœ‰ç»§ç»­ä½¿ç”¨è¿™ç§æ–¹å¼è¿›è¡Œæµ‹è¯•ï¼ŒåŸå› åœ¨äºéœ€è¦å¯¹æ¯ä¸ªç¬¬ä¸‰æ–¹æ¨¡å—è¿›è¡Œæ·»åŠ ï¼ˆæ–¹æ³•æœ¬èº«ä¸è®¤ï¼‰ã€‚
    # éœ€è¦çš„è¯å¯ä»¥å‚è€ƒï¼šhttps://github.com/ultralytics/thop é‡Œé¢çš„Define Custom Rules for Third-Party Modules
    # from ktransformers.sft.flops_utils.custom_profile import custom_profile

    # for module in model.modules():
    #     if not hasattr(module, 'total_ops'):
    #         module.register_buffer('total_ops', torch.zeros(1, dtype=torch.float64))
    #     if not hasattr(module, 'total_params'):
    #         module.register_buffer('total_params', torch.zeros(1, dtype=torch.float64))
            
    # # print(f"input:{input}")
    # for inputs in tqdm(train_dataloader):
    #     # input_ids = batch['input_ids']
    #     # del inputs['instruction']
    #     # del inputs['input']
    #     # del inputs['output']
    #     # output = model(**inputs)
    #     model.eval()
    #     content = inputs['instruction'][0] + inputs['input'][0]
    #     # flops,params = custom_profile(model, inputs=inputs, content=content, tokenizer=tokenizer, custom_ops={YourModule: count_your_model})
    #     # print('FLOPs = ' + str(flops / 1000 ** 3) + 'G')
    #     # print('Params = ' + str(params / 1000 ** 2) + 'M')

    #     messages = [{"role": "user", "content": content}]
    #     input_tensor = tokenizer.apply_chat_template(
    #         messages, add_generation_prompt=True, return_tensors="pt"
    #     )
    #     with torch.no_grad():
    #         # model(*inputs)
    #         # model.model to deal with the PeftModelForCaualLM temp
    #         prefill_and_generate(
    #             model.model, tokenizer, input_tensor.cuda(), max_new_tokens=1000, use_cuda_graph=False, mode = 'normal', force_think = False, chunk_prefill_size = 8192,
    #         )
    #     recursive_traverse(model)
    # -----------------æ¨¡å‹FLOPSæµ‹è¯•ï¼ˆTHOPæ–¹æ³•ï¼‰-----------------
    
    # -----------------è®¡ç®—å›¾æµ‹è¯•-----------------
    # output = model(input_ids=torch.tensor([[1,2,3]], dtype=torch.int32, device="cuda:0"))
    # loss = output.logits.mean()
        
    # dot = make_dot(loss, params=dict(model.named_parameters()))
    # dot.render("KT_compute_cpuinfer_moe_model_graph", format="svg")
    # -----------------è®¡ç®—å›¾æµ‹è¯•-----------------

    # -----------------KSFTå‰å‘æµ‹è¯•-----------------
    # with open("tmp/output_loss_KCPU.txt", "w") as file:
    #     file.write("Output (logits):\n")
    #     file.write(str(output.logits.cpu().detach().numpy()))  # è¿™é‡Œå°†å¼ é‡è½¬æ¢ä¸º numpy æ•°ç»„åå†™å…¥
    #     file.write("\n\nLoss:\n")
    #     file.write(str(loss.item()))  # è¿™é‡Œå°† loss çš„å€¼è½¬æˆå­—ç¬¦ä¸²
    # -----------------KSFTå‰å‘æµ‹è¯•-----------------
    
    # -----------------æ¨¡å‹å±‚ç¡®å®šæ€§æ¢¯åº¦æµ‹è¯•-----------------
    # disable_all_dropout(model)

    # def print_dropout_status(module, prefix=""):
    #     for name, child in module.named_children():
    #         if isinstance(child, nn.Dropout):
    #             print(f"{prefix}{name}: p={child.p}, training={child.training}")
    #         print_dropout_status(child, prefix + name + ".")
    
    # print("Dropoutå±‚çŠ¶æ€éªŒè¯ï¼š") # ç©ºè¾“å‡ºæˆ–è€…p=0å°±æ˜¯æˆåŠŸéªŒè¯
    # print_dropout_status(model)

    # for layer_path in target_layers:
    #     module = model.get_submodule(layer_path)
    #     hook = module.register_forward_hook(
    #         lambda m, i, o, ln=layer_path: record_layer_io(m, i, o, ln)
    #     )
    #     hooks.append(hook)
    # -----------------æ¨¡å‹å±‚ç¡®å®šæ€§æ¢¯åº¦æµ‹è¯•-----------------

    
    # -----------------æ¨¡å‹å±‚æ€§èƒ½åˆæ­¥æµ‹è¯•-----------------
    # if is_profiler:
    #     profiler = profile(
    #         activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],
    #         schedule=torch.profiler.schedule(
    #             wait=1,        # è·³è¿‡ç¬¬1æ­¥
    #             warmup=1,      # é¢„çƒ­ç¬¬2æ­¥
    #             active=1,      # ä»…è®°å½•æ¥ä¸‹æ¥3æ­¥ï¼ˆå‡å°‘æ˜¾å­˜å ç”¨ï¼‰
    #             repeat=1       # ä¸é‡å¤
    #         ),
    #         on_trace_ready=torch.profiler.tensorboard_trace_handler('./logs'),
    #         record_shapes=False,
    #         profile_memory=False, # å…³é—­å†…å­˜åˆ†æï¼Œé¿å…å ç”¨å¤§é‡å†…å­˜ï¼ˆç›®å‰è¿™ä¸ªæœåŠ¡å™¨CPUå†…å­˜ä¸æ˜¯å¾ˆå¤§ï¼‰
    #         with_stack=False
    #     )

    #     # transformerç‰ˆæœ¬ä½ä¸æ”¯æŒï¼Œä¸èƒ½ç›´æ¥åœ¨TrainingArgumentsé‡Œé¢å†™profiler_args
    #     # profiler_args = {
    #     #     "activities": [ProfilerActivity.CPU, ProfilerActivity.CUDA],  # åŒæ—¶ç›‘æ§CPUå’ŒCUDA
    #     #     "record_shapes": True,         # è®°å½•å¼ é‡å½¢çŠ¶
    #     #     "profile_memory": True,        # è®°å½•å†…å­˜æ¶ˆè€—
    #     #     "with_stack": True,            # è®°å½•è°ƒç”¨æ ˆä¿¡æ¯
    #     #     "on_trace_ready": torch.profiler.tensorboard_trace_handler('./logs'),  # è‡ªåŠ¨ä¿å­˜åˆ°TensorBoard
    #     #     "schedule": torch.profiler.schedule(
    #     #         wait=1,        # è·³è¿‡å‰1æ­¥
    #     #         warmup=1,      # é¢„çƒ­1æ­¥
    #     #         active=100,     # è®°å½•æ¥ä¸‹æ¥100æ­¥ï¼ˆè¦†ç›–å…¨éƒ¨è®­ç»ƒæ­¥ï¼‰
    #     #         repeat=1       # ä¸é‡å¤
    #     #     )
    #     # }

    #     trainer = KTrainer(
    #         model=model,
    #         train_dataset=train_dataset,
    #         args=training_args,            # ä½¿ç”¨ä¿®æ”¹åçš„å‚æ•°
    #         data_collator=DataCollatorForSeq2Seq(
    #             tokenizer, pad_to_multiple_of=8, return_tensors="pt", padding=True
    #         ),
    #         callbacks=[ProfilerCallback(profiler)]
    #     )

    #     with profiler:
    #         trainer.train()

    #     print("Training finished. Exporting profiler data...")
    #     with open("profiler_output.txt", "w") as f:
    #         f.write(profiler.key_averages().table(sort_by="cuda_time_total", row_limit=20))
    
    #   profiler.export_chrome_trace("trace.json")
    
    #   check_moe_gradients(model) # è°ƒè¯•ç»“æœï¼šæ— æ¢¯åº¦
    
    # -----------------æ¨¡å‹å±‚æ€§èƒ½åˆæ­¥æµ‹è¯•-----------------

    # verify_lora_layers(model)

    # model.save_pretrained(save_adapter_path)

    '''
    ----------------------- START: Lora Test -----------------------
    
    # print(f"LoRAå‰:{model}")

    # for name, module in model.named_modules():
    #     if "q_proj" in name or "kv_a_proj" in name or "o_proj" in name:
    #         print(name)

    # print_model_params(model)

    # model = KTransformersLinearLora()

    # inspect_device(model, '/home/yj/ktransformers/device1.txt')
    # with open('/home/yj/ktransformers/device1.txt', 'a') as file:
    #     file.write(f"Base model device: {model.base_model.device}\n")
        # file.write(f"LoRA adapter device: {model.lora_config['target_modules'].device}\n")
    # print(f"Base model device: {model.base_model.device}") 
    # print(f"LoRA adapter device: {model.lora_config['target_modules'].device}") 

    # print(f"LoRAå:{model}")

    # model = model.to('cuda')

    # for name, module in model.named_modules():
    #     module.register_forward_hook(forward_hook)

    # for name, parms in model.named_parameters():	
    #     # parms.requires_grad = True
    #     print('-->name:', name)
    #     print('-->para:', parms)
    #     print('-->grad_requirs:',parms.requires_grad)
    #     print('-->grad_fn:',parms.grad_fn)
    #     print('-->grad_value:',parms.grad)
    #     print("===")

    # # é€‰æ‹©ç‰¹å®šå±‚çš„è¾“å…¥è¾“å‡º
    # output = model(input_ids=torch.tensor([[1,2,3]], dtype=torch.int32, device="cuda:0"))
    # loss = output.logits.mean()

    # dot = make_dot(loss, params=dict(model.named_parameters()))
    # dot.render("KT_compute_graph", format="svg")

    # inspect_device(model, '/home/yj/ktransformers/device2.txt')
    # with open('/home/yj/ktransformers/device2.txt', 'a') as file:
    #     file.write(f"Base model device: {model.base_model.device}\n")
        # file.write(f"LoRA adapter device: {model.lora_config['target_modules'].device}\n")
    # print(f"Base model device: {model.base_model.device}") 
    # print(f"LoRA adapter device: {model.lora_config['target_modules'].device}") 

    # print_lora_params(model)

    # è¢«å¸¦profileçš„Traineræ›¿ä»£
    # trainer = KTrainer(
    #     model=model,
    #     train_dataset=train_dataset,
    #     args=transformers.TrainingArguments(
    #         output_dir=save_adapter_path,
    #         per_device_train_batch_size=1,
    #         gradient_accumulation_steps=16,
    #         num_train_epochs=10,
    #         learning_rate=3e-4,
    #         fp16=False,
    #         logging_steps=10,
    #         save_steps=200,
    #         # å¯é¢å¤–æ·»åŠ åˆ†å¸ƒå¼è®­ç»ƒä¼˜åŒ–å‚æ•° 
    #         dataloader_drop_last=True,
    #         ddp_find_unused_parameters=False 
    #     ),
    #     data_collator=DataCollatorForSeq2Seq(
    #         tokenizer, pad_to_multiple_of=8, return_tensors="pt", padding=True
    #     ),
    # )

    # model(input_ids=torch.tensor([[1,2,3]], dtype=torch.int32, device="cuda:0"))

    # trainer.train()

    # print_lora_params(model)

    # model = model.merge_and_unload()
    ----------------------- END: Lora Test -----------------------

    '''

def inject_lora_layer(model):

    lora_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM,
        target_modules=[
            "q_proj",
            "kv_a_proj_with_mqa",
            "kv_b_proj",
            "o_proj"
        ],
        r=8,
        lora_alpha=16,
        lora_dropout=0.0,
    )
    
    model = inject_adapter_in_model(lora_config, model)

    
